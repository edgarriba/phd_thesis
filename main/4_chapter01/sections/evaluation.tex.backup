\section{Experimental Evaluation}

The overall idea is showing that this helps the final task. In our case the final task is a semantic segmentation one (worldwide) in a non-supervised way. This is already a step compared to common approaches where only qualitative results are shown (double check \cite{vazquez:2014} where they include some weak evaluations).

Experiments, to be comprehensive should show:
- trained on dataset 1, test on dataset 2 with and without (the pure baseline) the correction.
- trained on dataset 1, different approaches (e.g., Reinhard) and evaluations (the more the better). This is complicated.
- Ideally, we should use KITTY and CamVid for evaluation... (there are not many more)

Tambien podemos usar el make3D, codigo available. Necesitamos probar que funciona. Make3D y Hoiem son muy genericos.
http://make3d.cs.cornell.edu/

\section{datasets}
 In this section, two different
experiments are conducted to validate our approach. The goal of
the first experiment is evaluating the ability of the proposed
learning scheme to infer the 3D scene structure from a single
image based on predictions from a classifier trained on a general
database. The goal of the second experiment is evaluating the
fusion of color planes for describing road textures and the
proposed road detection algorithm.

\subsection{Datasets}
\label{subsect:datasets}

Experiments are conducted on three different datasets of images
acquired using a camera mounted on a moving
platform~(\fig{fig:datasets}). The first dataset consists of
$2000$ on-board road images recorded while driving around
Barcelona at different days, different daytime and in different
scenarios. These images exhibit different backgrounds, different
lighting conditions and shadows and the presence of other vehicles
due to different traffic situations as shown
in~\subfig{fig:datasets}{a}. The second dataset is the
Cambridge-driving Labeled Video Database
(CamVid)~\cite{CamVidBBDD:PRL2008}. CamVid is a publicly available
collection of videos captured in the UK from the
perspective of a driving automobile with ground truth labels that
associate each pixel with one of $32$ semantic classes. This
dataset is divided in two scenarios: day and dusk. The former
consists of images acquired at daytime and the latter consists of
images acquired at nightfall exhibiting completely different
lighting conditions as shown in~\subfig{fig:datasets}{b}. Each of
these scenarios is further divided in two subsets: training and
testing. In our experiments, we focus on both testing sets for
evaluations and leave the training sets for validating different
convolutional neural network configurations (\ie, validation set).
The third dataset is the KITTY dataset~\cite{Geiger2013IJRR}.
KITTY is also a publicly available collection of image sequences
recorded while driving around Karlsruhe, Germany. In particular,
we consider urban images containing city, road and residential
scenarios. Therefore, the dataset is particularly challenging
since images exhibit highlights, cars, different road shapes
as shown in~\subfig{fig:datasets}{c}. Ground truth for this
dataset has been generated by manually annotating $300$ images
randomly selected from the complete dataset.

We are evaluating our algorithms using images recorded
with three different 'uncalibrated' cameras (\ie, different image
resolution and unknown camera parameters) for completely different
scenarios (Spain, Germany and United Kingdom) and at different
daytime. Only a subset of images from the first dataset is used for training the convolutional neural network while
quantitative evaluations are provided on $533$ images from the
other two datasets ($62$ images from Camvid-dusk test set, $171$
images from Camvid-day test set and $300$ images from KITTY)
without changing parameters or specific tuning (\ie, we assume
there is no validation set).


\begin{figure}[t!]
\begin{center}
\begin{tabular}{ccc}
\hspace{-0.05cm}\includegraphics[height=4cm]{./sections/figures/datasetA.eps}&\hspace{-0.05cm}
\includegraphics[height=4cm]{./sections/figures/datasetB.eps}&\hspace{-0.05cm}
\includegraphics[height=4cm]{./sections/figures/datasetC.eps}\\
(a)&(b)&(c)\\
\end{tabular}
\end{center}
\caption{Example of images from the three different datasets: a) Barcelona, b) Camvid day (left) and dusk (right) and c) KITTY (Germany). Images have different resolutions and are taken with different cameras at different scenarios and at different daytime. } \label{fig:datasets}
\end{figure}
\begin{figure*}[!t]
	\centering
	%\vspace{-1mm}
	\includegraphics[scale=0.9]{sections/figures/1TP.eps}
	%\vspace{-5mm}
	\caption{Label.}
	\label{fig:1TP}
	%\vspace{+0mm}
\end{figure*}


\begin{figure*}[!t]
	\centering
	%\vspace{-1mm}
	\includegraphics[scale=0.9]{sections/figures/random.eps}
	%\vspace{-5mm}
	\caption{Label.}
	\label{fig:random}
	%\vspace{+0mm}
\end{figure*}


%\singlespacing
%\renewcommand*\arraystretch{0.5}
\begin{table}
\centering
\resizebox{\columnwidth}{!}{%
%\scriptsize
%\tabcolsep=0.06cm
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\cline{2-9}\noalign{\vskip 1pt}
\multicolumn{1}{c|}{ } & \multicolumn{8}{|c|}{CamVid Dataset}\\
\cline{2-9}\noalign{\vskip 1pt}
\multicolumn{1}{c|}{ } & \multicolumn{2}{|c|}{1TP} & \multicolumn{2}{|c|}{6R0} & \multicolumn{2}{|c|}{16E5} & \multicolumn{2}{|c|}{05SV}\\
\cline{2-9}\noalign{\vskip 1pt}
\multicolumn{1}{c|}{ } & \textbf{OP} & \textbf{PC} & \textbf{OP} & \textbf{PC} & \textbf{OP} & \textbf{PC} & \textbf{OP} & \textbf{PC}\\
\hline
Hoiem (MSRC) Original & 0.61 & 0.38 &	\textbf{0.85} & \textbf{0.65} &	0.87 & 0.67 &	0.87 & 0.64\\
\hline
Make3D Original & 0.58 & 0.35 & 0.87 & 0.68 & 0.84 & 0.61 & 0.91 & 0.70\\
\hline
Darwin (KITTI) Original & 0.68 & 0.61 &	0.84 & 0.77 & \textbf{0.93} & \textbf{0.90} & \textbf{0.89} & \textbf{0.81}\\
\hline
CNN (Barcelona) Original & & & & & & & &\\
\hline\hline
Hoiem (MSRC) Adapted & \textbf{0.83} & \textbf{0.65} & 	0.84 & 0.63 &	\textbf{0.89} & \textbf{0.68} & 	0.87 & 0.64\\
\hline
Make3D Adapted & \textbf{0.71} & \textbf{0.51} & 0.87 & 0.68 & \textbf{0.85} & \textbf{0.63} & 0.91 & \textbf{0.71}\\
\hline
Darwin (KITTI) Adapted & \textbf{0.76} & \textbf{0.71} & 0.84 & 0.77 & 0.91 & 0.84 & 0.85 & 0.73\\
\hline
CNN (Barcelona) Adapted & & & & & & & &\\
\hline

\end{tabular}%
}
\caption{Caption}
\label{tab:results1} 
%\vspace{5mm}
\end{table}

\begin{table}
\centering
\resizebox{\columnwidth}{!}{%
%\scriptsize
%\tabcolsep=0.06cm
\begin{tabular}{|c|c|c|}
\cline{2-3}\noalign{\vskip 1pt}
\multicolumn{1}{c|}{ } & \multicolumn{2}{|c|}{KITTI Road Dataset}\\
\cline{2-3}\noalign{\vskip 1pt}
\multicolumn{1}{c|}{ } & \textbf{OP} & \textbf{PC}\\
\hline
Hoiem (MSRC) Original & 0.67 & 0.65 \\
\hline
Make3D Original & 0.62 & 0.57 \\
\hline
Darwin (Camvid) Original & 0.67 & 0.62 \\
\hline
CNN (Barcelona) & x & x \\
\hline\hline
Hoiem (MSRC) Adapted & 0.67 & 0.65 \\
\hline
Make3D Adapted & 0.61 & 0.57 \\
\hline
Darwin (Camvid) Adapted & 0.64 & 0.62 \\
\hline
CNN (Barcelona) Adapted & x & x \\
\hline
\end{tabular}%
}
\caption{Caption}
\label{tab:results2} 
%\vspace{5mm}
\end{table}