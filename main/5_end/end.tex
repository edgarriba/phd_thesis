%\graphicspath{{./main/5_end/figs/}}

\chapter{Conclusions and Future work}
\label{chap:end}

\section{Conclusions}

In this PhD dissertation we have addressed the problem of understanding driving scenes from vision at different levels, from the ``where am I in the scene?'' to the ``what is in my surroundings?''; from localization and mapping to the level of understanding involved in semantic segmentation and change detection. To achieve this we developed a strong tool-chain that included tools from robust statistics, such as L1 pose-averaging; tools from information theory, such as metric embedding and compressed regression; tools from Riemmanian geometry, such as manifold representation techniques and optimization; tools from compressive sensing, such as proximity operators, phase transitions and $\ell_0 \rightarrow \ell_1$ equivalences; tools from machine learning, such as the deconvolutional neural networks, the theory of domain adaptation and transfer learning; and tools from computer graphics, such as the realistic rendering of a city. Here, we take the opportunity to summarize the findings of this work.

In the first part of this dissertation we focused on visual localization, the ``where'', using geometric and algebraical techniques, addressing different versions of the Visual Odometry problem. Within this broad topic, we studied new formulations to improve robustness and computational efficiency of one of the core steps of Visual Odometry: ego-pose estimation. We proposed very fast alternatives based on oblivious embeddings and Lie-groups~\ref{chap:p1_01}. We then extended the robustness of our efficient alternatives, by reformulating the problem as a robust manifold averaging problem on a compressed evaluation space in chapter~\ref{chap:p1_02}. This was needed in order to compensate for the sensibility to noise of the approaches just based on $\ell_2$ embeddings, and we proved that $\ell_2$ embeddings could be used to achieve a fast and robust estimator in collaboration with averaging. In chapter~\ref{chap:p1_03}, we decided to face the problem of ego-pose estimation considering the intrinsic constraints arising from having a stereo rig moving through time. We modelled the main camera motion using rank and sparsity constraints, applying Robust PCA and compressed sensing techniques to discard outliers and obtain robust results. The approach behind the Robust PCA formulation was improved in chapter~\ref{chap:p1_04}, to decrease computational time while extending the applicability to the technique to large-scale cases (\ie, where larger amounts of data are involved). To this end we proposed a new formulation of Robust PCA as a specialized optimization on a product manifold. To optimize this manifold product space, we proposed an algorithm based on novel closed-form projectors with outstanding computational efficiency. We show that, in addition to ego-pose estimation, Robust PCA-like methods can be applied to a wide range of problems where outliers may be present and that our proposed approach has better theoretical and practical properties.

In the second part of this dissertation we focus on semantic segmentation and related problems, caring about ``what'' is in the scene. In chapter~\ref{chap:p2_01} we propose an automatic method to build maps that include rich semantic information of the scene as an offline approach. Then during an online stage visual localization is used as a proxy to recover the semantics associated to the static scene, which are further extended by detecting dynamic objects. This approach attempts to use the semantic map as a strong prior to speed the process of understanding up, leveraging computational resources to perform localization and detection of dynamic objects in real-time. However, the use of maps as strong priors brings several issues. First, using maps limits the level of autonomy of a vehicle, since it can only operate in those regions that haven been previously mapped. Secondly, those maps can be rendered useless very quickly, due to changes in the city. In addition, fast map updating is a complex and expensive process. 

We deal with the first of these problems in chapter~\ref{chap:p2_03}, trying to become map independent by proposing a novel architecture for real-time semantic segmentation based on deep learning principles. This effort is extended in chapter~\ref{chap:p2_04}, where we address data scarcity for semantic segmentation and related scene understanding problems by proposing a new synthetic platform called SYNTHIA. Synthetic data is combined with domain adaptation techniques, showing a cost-effective philosophy to produce accurate models usable in real domains. The topic of the model adaptation to different domains is also covered in chapter~\ref{chap:p2_02}, where we proposed an unsupervised method to adapt semantic segmentation models to drastic illumination changes.

In chapter~\ref{chap:p2_05}, we address fast map updating by reducing the bandwidth of the information to update, using change detection techniques. We derived a (semantic) change detection architecture out of our semantic segmentation model to produce a system capable of detecting and segmenting structural changes of the city due to man-made upgrades while ignoring visual seasonal changes. 

The intention behind studying and developing methods related to localization and mapping---which use maps as strong priors---,and methods that are map-free---as the case of real-time semantic segmentation---, is to bring perception redundancy to GAVs. We can conceive the combination of easy-to-update maps and real-time prior-less systems as the combination of two perception sensors. Such a combination would dramatically increase the reliability of autonomous cars, giving GAVs the power to operate in many different scenarios. For this reason we believe that the proposed approaches would have an important impact on the practical deployment of GAVs.


% Cada vez podemos desarrollar sistemas menos dependientes de prior knowledge en forma de mapa
% Los mapas se pueden usar para guardar informacion mas especifica y no tan general
% el uso de mundos virtuales...
% la importancia del domain adaptation

\section{Future Perspective}

From an academic point of view, driving scene understanding and its associated sub-tasks, such as semantic segmentation and change detection, have matured in a short period of time. As presented in this thesis, new models are showing very promising generalization capabilities and accurate results, when exposed to new unseen scenes. This has been possible due to the progress done in the machine learning techniques that are currently used to address these tasks and by the arrival of new and more challenging datasets such as SYNTHIA. However, there is yet a long path to explore in order to fulfil the expectations behind driving scene understanding.

First, we would like to rise a concern that has been around for a while: data scarcity and the data-versus-accuracy ratio. Currently, state-of-the-art techniques based on deep learning require an enormous amount of data with associated annotations. Semi-supervised and unsupervised alternatives place themselves as promising  alternatives in a close future, but nowadays they can not compete against the results provided by supervised methods. The current trend of embracing synthetic data is an important step forward in order to address more sophisticated problems using cost-effective solutions. Nevertheless, the generation of the data (and its associated annotations) is still a process decoupled from the learning algorithm. In other words, first the data is generated (usually by a third party) and then a learning method is adapted to make use of the data. A large proportion of that data is usually redundant and therefore plays no important role during the learning process. This leads to a situation in which much of the learning time is wasted re-exploring already assimilated cases, while other critical cases are being ignored. These facts lead to the logical conclusion that a data generator should be at the core of learning pipelines. Data should be generated on demand according to the current requirements of the model (for instance analysing validation error). Following this philosophy, standard learning procedures would become active learning procedures. How to bring this concept to practice is something that we are currently exploring.

Related to the previous point, we would like to highlight the need of exploring new problem representations in order to avoid unnecessary human-derived biases. This is probably one of the most relevant points discovered during the realization of this thesis. As previously described, we observed that slightly different ways of representing the ground truth information could lead to very different models, presenting a large gap in recognition accuracy. In other words, given a learning algorithm there are representations of a problem that are more suitable than others. This phenomenon seems to be occasioned by ambiguity introduced by humans and human biases. A possible approach to solve this issue could be to study the internal representations found in models trained to solve decision-making problems (\eg, making decisions on which action perform next from a list of possible actions)~\cite{BojarskiTDFFGJM16}, instead of understanding problems. To solve decision-making problems in an accurate fashion, agents need to acquire a good notion of how the scene is represented, in an indirect way. Could we use the information associated to the scene representation to avoid our biases?

A second important issue is to design new neural architectures specialized for scene understanding problems, \ie, including the constraints present on a given domain. We have already seen important improvements at this regard, with proposals such as the Recurrent Instance Segmentation~\cite{Romera-ParedesT15} and the Dilated Convolutions~\cite{YuKoltun2016}. In both cases, architectures are tailored around the main flaw of semantic segmentation, sub-segmentation due to a limited receptive field. At the light of the promising results offered by these approaches we would like to dedicate further efforts on effective ways of including domain constraints into deep learning architectures. 

% finally, verifying these models and produce industry-ready software...
We must also consider the gap between academically acceptable solutions and industrially acceptable solutions; a gap that is wide and still hard to bridge. In order validate a scene understanding system to achieve the level of quality requested by industry standards we may need to re-think some of the current assumptions. Current scene understanding models may not offer the required accuracy when moving to different geographic locations, \ie, they could suffer from generalization insufficiency. However, a practical alternative may be to accept that fact and compensate it by applying cost-effective domain adaptation for each new location. This alternative requires to keep exploiting and developing effective domain adaptation techniques for the different scene understanding problems, but would help to move these systems to production in a much shorter time-frame.

These, among many others, are the current open problems in scene understanding for driving scenarios. We hope that this summary and discussion could serve to motivate researchers to take some of these challenges, with the final goal of bringing autonomous driving a step closer. 

% ----------------------------------------------------------------
\section{Contributions}

In this PhD dissertation we have made both practical and theoretical contributions to autonomous driving from the point of view of visual localization-and-mapping techniques and visual scene understanding. In the scope of visual localization and mapping we have studied and propose novel approaches for the following problems:

\begin{itemize}
\item Fast and accurate compressed regression for pose-estimation in Visual Odometry
\item Robust optimization methods on Lie-groups and robust manifold averaging for Visual Odometry
\item New Manifold formulation as a triple direct product of Stiefel$\times$SPD$\times$Stiefel manifolds
\item Robust PCA and fast optimization on the Low-rank-Sparse manifold
\item Addressing Stereo Visual Odometry as a Low-rank-Sparse manifold
\end{itemize}

During the scene understanding part of this dissertation we have dealt with the problematic behind semantic segmentation of driving scenarios and (semantic) change detection. To this end we have propose new architectures based on deep deconvolutional networks along with new training methods and datasets. These contributions are summarized as follow:

\begin{itemize}
\item Efficient offline-online pipeline to perform real-time scene understanding via localization and retrieval
\item Novel training methods to improve deconvolutional neural network in the task of semantic segmentation of driving scenes
\item Novel training methods to improve change detection and semantic change detection results using deconvolutional neural networks
\end{itemize}

We have also put a special emphasis on practical problems when applying semantic segmentation in real scenarios, proposing new approaches based on unsupervised transfer learning and domain adaptation. To complement these results, we have also provided a method to compress state-of-the-art deconvolutional neural network to run on embedded devices. These contributions are summarized as follow:

\begin{itemize}
\item Efficient unsupervised transfer-learning approach to adapt semantic segmentation models on-the-fly to new illumination conditions
\item Novel domain adaptation methods to improve accuracy when transferring from Virtual-to-Real scenes
\item Novel training methods to deal with data multi-modality in driving semantic segmentation
\item A novel technique to perform compression of devoncolutional neural networks to use them in embedded contexts 
\end{itemize}



\section{Patents}
\begin{itemize}
\item Network compression via Transfer-Learning and Optimization methods for Embedded Contexts and Autonomous Vehicles. Filed 2016, Toshiba Research Corporation, main intellectual author.
\end{itemize}

\section{Scientific Articles}

This dissertation has led to the following communications:

\subsection{Submitted Journals}
\begin{itemize}
	\item \textbf{German Ros}, Jose Alvarez and Julio Guerrero. Motion estimation via robust decomposition with
constrained rank. IEEE Transactions on Intelligent Vehicles, 2016
\item \textbf{German Ros}, Simon Stent, Pablo~F. Alcantarilla, and Tomoki Watanabe. Training constrained deconvolutional networks for road scene semantic segmentation. IEEE Transactions on Intelligent Transportation Systems, 2016
\item \textbf{German Ros}, Julio Guerrero, Angel Sappa, Daniel Ponsa, and Antonio Lopez. Fast and robust fixed-rank matrix recovery. International Journal on Computer Vision, 2016
\end{itemize}

\subsection{Book Chapters}
\begin{itemize}
\item \textbf{German Ros}, Laura Sellart, Gabriel Villalonga, Elias Maidanik, Francisco Molero, Marc Garcia, Adriana Cedeo, Francisco Perez, Didier Ramirez, Eduardo Escobar, David Vazquez, and Antonio M. Lopez. Semantic Segmentation of Urban Scenes via Domain Adaptation of SYNTHIA. Srpinger editorial, Domain Adaptation for Computer Vision Applications, 2016
\end{itemize}

\subsection{International Conferences and Workshops}
\begin{itemize}
\item \textbf{German Ros}, Laura Sellart, Joanna Materzynska, David Vazquez, and Antonio
  Lopez. The {SYNTHIA} dataset: A large collection of synthetic images for
  semantic segmentation of urban scenes. In Proc. of Conference on Computer Vision and Pattern Recognition (CVPR). Las Vegas, USA (\textbf{short-oral}), 2016.
  
\item Pablo Alcantarilla, Simon Stent, \textbf{German Ros}, Roberto Arroyo, and Riccardo
  Gherardi. Street-view change detection with deconvolutional networks. In Proc. of Robotics: Science and Systems (RSS). Michigan, USA, (\textbf{nominated to best systems paper award}), 2016

\item \textbf{German Ros} and Jose Alvarez. Unsupervised image transformation for outdoor semantic labelling. In Proc.  of IEEE Intelligent Vehicles Symposium (IV). Seoul, Korea, 2015

\item Alejandro Gonzalez, Gabriel Villalonga, \textbf{German Ros}, David Vazquez, and Antonio
  Lopez. {3D}-guided multiscale sliding window for pedestrian detection. In Proc. Iberian Conference on Pattern Recognition and Image Analysis (Ibpria). Santiago de Compostela, Spain, 2015


\item \textbf{German Ros}, Sebastian Ramos, Manuel Granados, Amir~H. Bakhtiary, David Vazquez,
  and Antonio Lopez. Vision-based offline-online paradigm for autonomous driving. In Proc. IEEE Winter Conference on Applications of Computer Vision (WACV). Hawaii, USA, 2015
  
\item \textbf{German Ros}, Julio Guerrero, Angel Sappa, Daniel Ponsa, and Antonio Lopez. Fast and robust l1-averaging-based pose estimation for driving scenarios. In Proc. British Machine Vision Conference (BMVC)., Bristol, UK, 2013
  
\item \textbf{German Ros}, Julio Guerrero, Angel Sappa, Daniel Ponsa, and Antonio Lopez. {VSLAM} pose initialization via {L}ie-groups and {L}ie-algebras optimization. In Proc. IEEE International Conference on Robotics and Automation (ICRA). Karlsruhe, Germany, 2013

\item \textbf{German Ros}, Angel Sappa, Daniel Ponsa, and Antonio Lopez. Visual slam for driverless cars: A brief survey. In Proc. IEEE Workshop on Navigation, Perception, Accurate Positioning and Mapping for Intelligent Vehicles. Alcala de Henares, Spain, 2012

\end{itemize}

\section{Contributed Code and Datasets}

\begin{itemize}
\item \textbf{SYNTHIA virtual dataset}: A virtual dataset for driving scene understanding task, with focus on semantic segmentation, instance segmentation, change detection and localization and mapping. \url{http://synthia-dataset.net}

\item \textbf{The Multi-Domain Road Scene Semantic Segmentation (MDRS3)}: a dataset for semantic segmentation of urban scenes where multiple domains are combined extended and improved from public datasets. \url{http://www.toshiba.eu/eu/Cambridge-Research-Laboratory}

\item \textbf{The KITTI Semantic Dataset}: A collection of semantic annotations for part of the KITTI Visual Odometry dataset. \url{http://adas.cvc.uab.es/s2uad}

\item \textbf{MatConvNet-DeconvNet}: A branch of the MatConvNet deeplearning framework, improved and specialized to work with deconvolutional neural networks for several problems, such as semantic segmentation, optical flow, depth estimation, pose estimation, etc. \url{https://github.com/germanRos/MatConvNet-DeconvNet}

\item \textbf{Chainer-deconv}: A branch of the popular Chainer deep learning framework, improved and specialized to work with deconvolutional neural networks for several problems, such as semantic segmentation, change detection, depth estimation and network compression. \url{https://github.com/germanRos/chainer-deconv}

\item \textbf{Yet Another Semantic Segmentator in 3D (YASS3D)}: A general semantic segmentation framework over 3D point-clouds, using 3D features and standard linear SVM and CRFs. \url{https://github.com/germanRos/YASS3D}

\item \textbf{Fixed-Rank Alternated Direction Method with Augmented Lagrange Multiplier (FRADM)}: A general algorithm to perform Robust PCA via Manifold optimization with a new formulation on a product manifold. \url{https://github.com/germanRos/FRADM}

\item\textbf{ Robust L1-Averaging for Visual Odometry}: A method to perform robust and very fast model averaging on the $\mathbb{SE}(3)$ manifold using compressed regression with application to Visual Odometry. \url{https://github.com/germanRos/l1avgvo}

\item \textbf{Ego-motion $\mathbb{SE}(3)$ optimization by Lie-group optimization (LieOpt)}: A method to perform compressed optimization on Lie-groups using algebraical cost functions, with application to pose estimation. \url{https://github.com/dehabu/Lieopt}
\end{itemize}

\section{Scientific Dissemination}

\subsection{Invited Talks}
\begin{itemize}
\item  \textit{Exploiting Virtual Worlds and Domain Adaptation for Driving Scene Understanding}, at Zoox, Palo Alto, USA, 2016
\item  \textit{The {SYNTHIA} dataset: A large collection of synthetic images for
  semantic segmentation of urban scenes}, International Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, USA, 2016
\item  \textit{Semantic Segmentation for Driving Scenarios: On virtual worlds}, Industrial Robotics Institute, CSIC-UPC, Barcelona, Spain, 2016
\item  \textit{Semantic Segmentation for Driving Scenarios: On Virtual Worlds and Embedded Platforms}, at Oxford University, Engineering Dept., Torr’s Group, Oxford, UK, 2016
\item  \textit{On Practical Semantic Segmentation for Autonomous Driving}, at NVIDIA Research, New Jersey, USA, 2016.

\item \textit{On Scene Understanding on Virtual Worlds}, at Xerox Research Center Europe, Grenoble, France, 2016

\item \textit{Vision-based offline-online paradigm for autonomous driving}, at the IEEE Winter Conference on Applications of Computer Vision (WACV), Hawaii, USA, 2015

\item \textit{Robust Matrix Decomposition with Fixed-Rank Constraint}, at UC Louvain in the ICTEAM Seminars in Mathematical Engineering, Belgium, 2014

\item \textit{On 3D Semantic Maps for Vision-based Offline-Online Autonomous Driving}, at NICTA, Canberra Research Lab, Canberra, Australia, 2013

\item \textit{Autonomous driving: when 3D mapping meets semantics}, at the Workshop of Computer Vision in Vehicle Technology: From Earth to Mars, in conjunction with the IEEE International Conference on Computer Vision, Sydney, Australia, 2013

\item \textit{3D Scene Understanding}, at the Department of Informatics and Systems, Universidad de Zaragoza,, Zaragoza, Spain, 2013

\item \textit{Visual slam for driverless cars: A brief survey}, at the IEEE Workshop on Navigation, Perception, Accurate Positioning and Mapping for Intelligent Vehicles, in conjunction with the Intelligent Vehicles Symposium, Alcala de Henares, Spain, 2012
\end{itemize}

\subsection{Demos}
\begin{itemize}
\item \textit{SYNTHIA meets Virtual KITTI} at the International Conference on Computer Vision and Pattern Recognition, Las Vegas, USA, 2016
\end{itemize}

\subsection{In the Media}
\begin{itemize}
\item \textit{Meet Synthia, the virtual driving school for autonomous cars}, Gizmag, June, 2016
\item \textit{Customizing your car is about to get more futuristic}, CNET.com, July, 2016
\item \textit{{SYNTHIA} is a massive virtual city where autonomous vehicles can safely learn how to drive}, Digitaltrends, June, 2016
\item \textit{Welcome to {SYNTHIA} City: Virtual world created so AI cars can learn to drive}, Daily Mail Online, June, 2016
\item \textit{Sim City Created for Self-Driving Cars}, Seeker, June, 2016
\item \textit{Investigadores de la UAB crean un videojuego para los coches autónomos}, La Vanguardia, Spain, June, 2016
\item \textit{Investigadores de Barcelona crean un videojuego para acelerar la llegada de los coches autónomos}, El Mundo, Spain, June, 2016
\item \textit{El videojuego para que los coches autónomos aprendan}, ABC, Spain, June, 2016
\item \textit{Mira, màquina}, magazine El Temps, Barcelona, July, 2016
\end{itemize}